# 🖐️ Hand Gestures Translator  
![Project_Image](https://github.com/user-attachments/assets/2b4af766-afb5-46de-b7ad-a40fafbc198c)

A real-time **Sign Language Recognition System** that translates hand gestures into **text and speech**, supporting **English and Arabic alphabets** and **digits**.  
It helps people who cannot speak communicate with those who don’t understand sign language.  

---

## ✨ Features  
- ⚡ Real-time gesture recognition using **MediaPipe + OpenCV**  
- 🌳 **Random Forest model** for classification (fast, accurate, lightweight)  
- 🖥️ **GUI** with live video, reset & speak buttons  
- 🔊 **Text-to-Speech (TTS)** support → letters/sentences can be spoken aloud  
- 🔌 **IoT Integration**: ESP8266 + Arduino + LCD for hardware output  
- 📱 **Mobile App** (MIT App Inventor) for gesture-to-text with speech support  

---

## 🛠️ Tech Stack  
- 🤖 **AI/ML**: MediaPipe, OpenCV, Random Forest (scikit-learn)  
- 🔧 **IoT**: Arduino UNO, ESP8266, LCD Display (I2C)  
- 📱 **Mobile**: MIT App Inventor  
- 🔊 **TTS**: pyttsx3, gTTS  

---

## 🚀 Future Updates
- 📝 Translate gestures into full words
- 📊 Expand dataset for better accuracy

- ☁️ Cloud integration for remote usage

---

## 📌 Goal  
**Making simple communication possible between people who are unable to speak and those who cannot understand sign language.**  
