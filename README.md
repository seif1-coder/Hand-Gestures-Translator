# ğŸ–ï¸ Hand Gestures Translator  
![Project_Image](https://github.com/user-attachments/assets/2b4af766-afb5-46de-b7ad-a40fafbc198c)

A real-time **Sign Language Recognition System** that translates hand gestures into **text and speech**, supporting **English and Arabic alphabets** and **digits**.  
It helps people who cannot speak communicate with those who donâ€™t understand sign language.  

---

## âœ¨ Features  
- âš¡ Real-time gesture recognition using **MediaPipe + OpenCV**  
- ğŸŒ³ **Random Forest model** for classification (fast, accurate, lightweight)  
- ğŸ–¥ï¸ **GUI** with live video, reset & speak buttons  
- ğŸ”Š **Text-to-Speech (TTS)** support â†’ letters/sentences can be spoken aloud  
- ğŸ”Œ **IoT Integration**: ESP8266 + Arduino + LCD for hardware output  
- ğŸ“± **Mobile App** (MIT App Inventor) for gesture-to-text with speech support  

---

## ğŸ› ï¸ Tech Stack  
- ğŸ¤– **AI/ML**: MediaPipe, OpenCV, Random Forest (scikit-learn)  
- ğŸ”§ **IoT**: Arduino UNO, ESP8266, LCD Display (I2C)  
- ğŸ“± **Mobile**: MIT App Inventor  
- ğŸ”Š **TTS**: pyttsx3, gTTS  

---

## ğŸš€ Future Updates
- ğŸ“ Translate gestures into full words
- ğŸ“Š Expand dataset for better accuracy

- â˜ï¸ Cloud integration for remote usage

---

## ğŸ“Œ Goal  
**Making simple communication possible between people who are unable to speak and those who cannot understand sign language.**  
